# bot.py ‚Äî async + aiogram 3.7+, qty-–∞–ª–∏–∞—Å—ã, —É–º–Ω—ã–π –ø–æ–∏—Å–∫ –∫–æ–ª–æ–Ω–æ–∫,
# —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Å—Ç–∞—Ç—É—Å—ã, –¥–≤—É—Ö—à–∞–≥–æ–≤–∞—è —Å—Ö–µ–º–∞ –æ–±–ª–∞—Å—Ç—å‚Üí—Ä–∞–π–æ–Ω,
# —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ "–∞–≤—Ç–æ—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç / –ø—Ä–æ—á–µ–µ", –≤—ã–≤–æ–¥ —Ç–∏–ø–æ–≤ –ø–æ –æ–±–ª–∞—Å—Ç–∏ –∏ –ø–æ —Ä–∞–π–æ–Ω—É
# (—Å —Ä–∞–∑—Ä–µ–∑–æ–º –ø–æ —Å—Ç–∞—Ç—É—Å–∞–º –≤ —Ä–∞–π–æ–Ω–µ) + GPS-—É—á—ë—Ç –ø–æ –æ–±–ª–∞—Å—Ç—è–º
# –∏ —Ä–∞–∑–¥–µ–ª—å–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è –∞–≤—Ç–æ—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞ –∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è –ø–æ –æ–±–ª–∞—Å—Ç–∏
# + —Ä–∞–∑–¥–µ–ª—å–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –≤ ¬´–û–±—â–µ–µ –ø–æ —Ä–µ—Å–ø—É–±–ª–∏–∫–µ¬ª.

import asyncio
import logging
from datetime import datetime, timedelta
from pathlib import Path
import os
from typing import Dict, Tuple, Optional, List
import re
import time
import html
import random
import unicodedata
from collections import defaultdict

from aiogram import Bot, Dispatcher, types, F, BaseMiddleware
from aiogram.filters import Command
from aiogram.utils.keyboard import InlineKeyboardBuilder, ReplyKeyboardBuilder
from aiogram.exceptions import TelegramBadRequest
from aiogram.client.default import DefaultBotProperties
from aiogram.enums import ParseMode

import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
from dotenv import load_dotenv

# ---------- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ ----------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("bot.log", encoding="utf-8"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ---------- .env / –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è ----------
from dotenv import load_dotenv
import json

BASE_DIR = Path(__file__).resolve().parent

# –õ–æ–∫–∞–ª—å–Ω–æ (–Ω–∞ —Ç–≤–æ—ë–º –∫–æ–º–ø–µ) —ç—Ç–æ –ø—Ä–æ—á–∏—Ç–∞–µ—Ç .env.
# –ù–∞ Render ‚Äî –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç, –∏ –≤–æ–∑—å–º—ë—Ç –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ Environment.
load_dotenv()

BOT_TOKEN = os.getenv("BOT_TOKEN")
if not BOT_TOKEN:
    raise RuntimeError("–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è BOT_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")

# ---------- Google Sheets —á–µ—Ä–µ–∑ GOOGLE_CREDS_JSON ----------
SCOPES = [
    "https://www.googleapis.com/auth/spreadsheets",
    "https://www.googleapis.com/auth/drive",
]

google_creds_json = os.getenv("GOOGLE_CREDS_JSON")
if not google_creds_json:
    raise RuntimeError("–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è GOOGLE_CREDS_JSON –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")

try:
    creds_info = json.loads(google_creds_json)
    creds = Credentials.from_service_account_info(creds_info, scopes=SCOPES)
    gc = gspread.authorize(creds)
    logger.info("–£—Å–ø–µ—à–Ω–∞—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –≤ Google Sheets")
except Exception as e:
    logger.error(f"–û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ Google Sheets: {e}")
    raise

# ---------- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ----------
REGION_SHEETS = {
    "–ê–Ω–¥–∏–∂–æ–Ω":             os.getenv("SHEET_ANDIJON"),
    "–§–∞—Ä“ì–æ–Ω–∞":             os.getenv("SHEET_FARGONA"),
    "–ù–∞–º–∞–Ω–≥–∞–Ω":            os.getenv("SHEET_NAMANGAN"),
    "–¢–æ—à–∫–µ–Ω—Ç —à–∞“≥—Ä–∏":       os.getenv("SHEET_TASHKENT"),
    "–¢–æ—à–∫–µ–Ω—Ç –≤–∏–ª.":        os.getenv("SHEET_TASHKENT_VIL"),
    "–°–∞–º–∞—Ä“õ–∞–Ω–¥":           os.getenv("SHEET_SAMARKAND"),
    "–ñ–∏–∑–∑–∞—Ö":              os.getenv("SHEET_JIZZAKH"),
    "–°–∏—Ä–¥–∞—Ä—ë":             os.getenv("SHEET_SIRDARYO"),
    "“ö–∞—à“õ–∞–¥–∞—Ä—ë":           os.getenv("SHEET_QASHQADARYO"),
    "–°—É—Ä—Ö–æ–Ω–¥–∞—Ä—ë":          os.getenv("SHEET_SURXONDARYO"),
    "–ë—É—Ö–æ—Ä–æ":              os.getenv("SHEET_BUKHARA"),
    "–ù–∞–≤–æ–∏–π":              os.getenv("SHEET_NAVOIY"),
    "–•–æ—Ä–∞–∑–º":              os.getenv("SHEET_XORAZM"),
    "“ö–æ—Ä–∞“õ–∞–ª–ø–æ“ì–∏—Å—Ç–æ–Ω":     os.getenv("SHEET_QORAQALPOG"),
    "–î–∞–º—Ö—É–∂–∞":             os.getenv("SHEET_DAMXOJA"),
    "–ú—É—Å–∞—Ñ—Ñ–æ":             os.getenv("SHEET_MUSAFFO"),
    "–ß–∏–º–≥–∞–Ω-–ß–∞—Ä–±–æ“ì":       os.getenv("SHEET_CHIMGAN"),
    "–°—É–≤—û–ª—á–∞–≥–∏—á—Ö–∏–∑–º–∞—Ç–∏":   os.getenv("SHEET_SUVULCHAGICH"),
}

# –ö–æ–ª–æ–Ω–∫–∏ ¬´–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é¬ª
COL_TYPE   = "–¢–µ—Ö–Ω–∏–∫–∞ —Ç—É—Ä–∏"
COL_REGION = "–ë–∏—Ä–∏–∫—Ç–∏—Ä–∏–ª–≥–∞–Ω —à–∞—Ö–∞—Ä —ë–∫–∏ —Ç—É–º–∞–Ω"
COL_QTY    = "‚Ññ –¢/—Ä"   # –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ qty, –æ—Å—Ç–∞–≤–ª–µ–Ω–æ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
COL_STATUS = "–•–æ–ª–∞—Ç–∏"

# –ê–ª–∏–∞—Å—ã
STATUS_ALIASES = [
    "–•–æ–ª–∞—Ç–∏", "“≤–æ–ª–∞—Ç–∏", "–°—Ç–∞—Ç—É—Å", "–°–æ—Å—Ç–æ—è–Ω–∏–µ", "“≤–æ–ª–∞—Ç", "Holati", "Status",
    "–¢–µ—Ö–Ω–∏–∫–∞ —Ö–æ–ª–∞—Ç–∏", "–¢–µ—Ö–Ω–∏–∫–∞ “≥–æ–ª–∞—Ç–∏", "–¢–µ—Ö–Ω–∏–∫–∞ —Å—Ç–∞—Ç—É—Å—ã", "–¢–µ—Ö–Ω–∏–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏–µ"
]
TYPE_ALIASES   = [COL_TYPE, "–¢–µ—Ö–Ω–∏–∫–∏ —Ç—É—Ä–∏", "–¢–∏–ø —Ç–µ—Ö–Ω–∏–∫–∏", "–¢—É—Ä–∏ —Ç–µ—Ö–Ω–∏–∫–∞", "–¢–µ—Ö–Ω–∏–∫–∞ —Ç—û—Ä–∏", "–í–∏–¥ —Ç–µ—Ö–Ω–∏–∫–∏", "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ç–µ—Ö–Ω–∏–∫–∏"]
REGION_ALIASES = [COL_REGION, "–ì–æ—Ä–æ–¥/—Ä–∞–π–æ–Ω", "–†–∞–π–æ–Ω", "–¢—É–º–∞–Ω", "–ù–∞—Å–µ–ª–µ–Ω–Ω—ã–π –ø—É–Ω–∫—Ç", "–®–∞—Ö–∞—Ä/—Ç—É–º–∞–Ω", "–®–∞—Ö–∞—Ä —ë–∫–∏ —Ç—É–º–∞–Ω"]
QTY_ALIASES    = ["–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", "–ö–æ–ª-–≤–æ", "–°–æ–Ω–∏", "Qty", "Count"]

# –ê–ª–∏–∞—Å—ã –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏ —Å GPS/—Ç—Ä–µ–∫–µ—Ä–æ–º
TRACKER_ALIASES = [
    "GPS",
    "Gps",
    "gps",
    "–¢—Ä–µ–∫–µ—Ä",
    "–¢—Ä–µ–∫–µ—Ä —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω",
    "–ù–∞–ª–∏—á–∏–µ —Ç—Ä–µ–∫–µ—Ä–∞",
    "–ù–∞–ª–∏—á–∏–µ GPS",
    "GPS —Ç—Ä–µ–∫–µ—Ä",
    "GPS-—Ç—Ä–µ–∫–µ—Ä",
    "GPS / –ì–õ–û–ù–ê–°–°",
    "GPS/–ì–õ–û–ù–ê–°–°",
    "GPS –±–∏–ª–∞–Ω —Ç–∞—ä–º–∏–Ω–ª–∞–Ω–≥–∞–Ω–ª–∏–≥–∏",
    "GPS –±–∏–ª–∞–ø–Ω —Ç–∞—ä–º–∏–Ω–ª–∞–Ω–≥–∞–Ω–ª–∏–≥–∏",
]

# ---------- –ö–µ—à/–∫–≤–æ—Ç—ã ----------
CACHE: Dict[str, Tuple[pd.DataFrame, datetime]] = {}
CACHE_TTL = timedelta(minutes=30)
LAST_API_CALL = datetime.min
API_DELAY = 2.0
PARALLEL_LIMIT = 4

# ---------- Callback-—Å–æ–∫—Ä–∞—â–µ–Ω–∏—è ----------
CB_MAP: Dict[str, str] = {}  # id -> payload


def put_cb(payload: str) -> str:
    key = str(abs(hash(payload)))
    CB_MAP[key] = payload
    return key


def get_cb(key: str) -> Optional[str]:
    return CB_MAP.get(key)


# ---------- –•–µ–ª–ø–µ—Ä—ã ----------
def esc(s: str) -> str:
    return html.escape(str(s or ""))


def _normalize_header(s: str) -> str:
    s = str(s or "").strip().lower()
    s = s.replace("“≥", "—Ö")  # “≤‚âà–•
    s = re.sub(r"\s+", "", s)
    return s


def _norm_map(cols: List[str]) -> Dict[str, str]:
    return {_normalize_header(c): c for c in cols}


def find_column(df: pd.DataFrame, aliases: List[str]) -> Optional[str]:
    """
    1) —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ (–ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏),
    2) –ø–æ–¥—Å—Ç—Ä–æ–∫–∞ (–±–µ—Ä—ë–º —Å–∞–º—ã–π –∫–æ—Ä–æ—Ç–∫–∏–π –º–∞—Ç—á),
    3) —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: —Ç–æ–∫–µ–Ω—ã –¥–ª—è —Å—Ç–∞—Ç—É—Å–∞/—Ä–µ–≥–∏–æ–Ω–∞/—Ç–∏–ø–∞.
    """
    norm_cols = _norm_map(list(df.columns))

    # 1) —Ç–æ—á–Ω–æ–µ
    for a in aliases:
        k = _normalize_header(a)
        if k in norm_cols:
            return norm_cols[k]

    # 2) –ø–æ–¥—Å—Ç—Ä–æ–∫–∞
    best = None
    for a in aliases:
        ka = _normalize_header(a)
        for nc, orig in norm_cols.items():
            if ka and ka in nc:
                if best is None or len(nc) < len(_normalize_header(best)):
                    best = orig
    if best:
        return best

    # 3) —ç–≤—Ä–∏—Å—Ç–∏–∫–∞
    token_sets = [
        {"—Ö–æ–ª–∞—Ç", "“≥–æ–ª–∞—Ç", "holat", "status", "—Å–æ—Å—Ç–æ—è–Ω–∏–µ"},   # —Å—Ç–∞—Ç—É—Å
        {"—à–∞—Ö–∞—Ä", "—Ç—É–º–∞–Ω", "—Ä–∞–π–æ–Ω", "–≥–æ—Ä–æ–¥"},                 # —Ä–µ–≥–∏–æ–Ω/–Ω–∞—Å.–ø—É–Ω–∫—Ç
        {"—Ç–µ—Ö–Ω–∏–∫–∞", "—Ç–∏–ø", "—Ç—É—Ä", "–≤–∏–¥"},                     # —Ç–∏–ø —Ç–µ—Ö–Ω–∏–∫–∏
    ]
    for tokens in token_sets:
        for nc, orig in norm_cols.items():
            if any(tok in nc for tok in tokens):
                return orig

    return None


APOSTS = {"'", " º", "‚Äô", " π", "‚Ä≤", "`", "¬¥", " Ω", "Íûå", " ª"}


def _prenorm(s: str) -> str:
    s = unicodedata.normalize("NFKC", s or "")
    for a in APOSTS:
        s = s.replace(a, "'")
    return s.replace("\u00A0", " ")


# ---- –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–∏–ø–∞ —Ç–µ—Ö–Ω–∏–∫–∏ ----
def normalize_tech_type(tech_type: str) -> Optional[str]:
    if not isinstance(tech_type, str) or tech_type.strip() == "":
        return None
    raw = tech_type
    normalized = _prenorm(tech_type).strip().lower()
    normalized = re.sub(r"[^\w\s]", " ", normalized)
    normalized = re.sub(r"\s+", " ", normalized).strip()
    if not normalized or normalized in ["nan", "none", "null", ""]:
        return None

    # –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—Ç—Ä–æ–∫–æ–≤—ã–µ –∏—Ç–æ–≥–∏ / —Å–ª—É–∂–µ–±–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
    summary_keywords = ["–∂–∞–º–∏", "–∏—Ç–æ–≥–æ", "–±–∞—Ä—á–∞—Å–∏", "–≤—Å–µ–≥–æ", "jami", "all"]
    if any(k in normalized for k in summary_keywords):
        return None

    type_mapping = {
        "–ø–æ–≥—Ä—É–∑—á–∏–∫": "–ü–æ–≥—Ä—É–∑—á–∏–∫",
        "–º–∏–Ω–∏ –±–æ—Ä—Ç–æ–≤–æ–π": "–ú–∏–Ω–∏ –±–æ—Ä—Ç–æ–≤–æ–π",
        "–º–∏–Ω–∏–∏ –±–æ—Ä—Ç–æ–≤–æ–π": "–ú–∏–Ω–∏ –±–æ—Ä—Ç–æ–≤–æ–π",
        "–º–∏–∫—Ä–æ –±–æ—Ä—Ç–æ–≤–æ–π": "–ú–∏–Ω–∏ –±–æ—Ä—Ç–æ–≤–æ–π",
        "—ç–≤–∞–∫—É–∞—Ç–æ—Ä": "–≠–≤–∞–∫—É–∞—Ç–æ—Ä",
        "—Ö–ª–æ—Ä–æ–≤–æ–∑": "–•–ª–æ—Ä–æ–≤–æ–∑",
        "—Å–∞–º–æ—Å–≤–∞–ª": "–°–∞–º–æ—Å–≤–∞–ª",
        "—ç–∫—Å–∫–∞–≤–∞—Ç–æ—Ä": "–≠–∫—Å–∫–∞–≤–∞—Ç–æ—Ä",
        "—Ç—Ä–∞–∫—Ç–æ—Ä": "–¢—Ä–∞–∫—Ç–æ—Ä",
        "–±—É–ª—å–¥–æ–∑–µ—Ä": "–ë—É–ª—å–¥–æ–∑–µ—Ä",
        "–∞–≤—Ç–æ–∫—Ä–∞–Ω": "–ê–≤—Ç–æ–∫—Ä–∞–Ω",
        "–±–µ—Ç–æ–Ω–æ–º–µ—à–∞–ª–∫–∞": "–ë–µ—Ç–æ–Ω–æ–º–µ—à–∞–ª–∫–∞",
        "—Ü–∏—Å—Ç–µ—Ä–Ω–∞": "–¶–∏—Å—Ç–µ—Ä–Ω–∞",
        "—Ñ—É—Ä–≥–æ–Ω": "–§—É—Ä–≥–æ–Ω",
        "—Ä–µ—Ñ—Ä–∏–∂–µ—Ä–∞—Ç–æ—Ä": "–†–µ—Ñ—Ä–∏–∂–µ—Ä–∞—Ç–æ—Ä",
        "–≥–∏–¥—Ä–æ–ª–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è": "–ì–∏–¥—Ä–æ–¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è",
        "–≥–∏–¥—Ä–æ–ª–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π": "–ì–∏–¥—Ä–æ–¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è",
        "–≥–∏–¥—Ä–æ–¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è": "–ì–∏–¥—Ä–æ–¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è",
        "–≥–∏–¥—Ä–æ–¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π": "–ì–∏–¥—Ä–æ–¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è",
        "–≥–∏–¥—Ä–∞–≤–ª–∏—á–µ—Å–∫–∞—è": "–ì–∏–¥—Ä–æ–¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è",
        "–ª–∞–±–æ–ª–∞—Ç–æ—Ä–Ω–∞—è": "–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è",
        "–ª–æ–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è": "–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è",
        "–ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è": "–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è",
        "–∫–∞–º–∞–∑": "–ö–∞–º–∞–∑",
        "–∑–∏–ª": "–ó–ò–õ",
        "–≥–∞–∑–µ–ª—å": "–ì–ê–ó–µ–ª—å",
        "—É–∞–∑": "–£–ê–ó",
        "–∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä": "–ö–æ–º–ø—Ä–µ—Å—Å–æ—Ä",
        "–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä": "–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä",
        "–∞–≤—Ç–æ–±—É—Å": "–ê–≤—Ç–æ–±—É—Å",
        "–º–∏–∫—Ä–æ–∞–≤—Ç–æ–±—É—Å": "–ú–∏–∫—Ä–æ–∞–≤—Ç–æ–±—É—Å",
        "–º–∞—à–∏–Ω–∞": "–ú–∞—à–∏–Ω–∞",
        "–≥—Ä—É–∑–æ–≤–∏–∫": "–ì—Ä—É–∑–æ–≤–∏–∫",
    }
    for key, standard_name in type_mapping.items():
        if key in normalized:
            return standard_name
    return raw.strip().capitalize()


# ---- –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç–∞—Ç—É—Å–∞ ----
def normalize_status(status: str) -> str:
    if not isinstance(status, str) or status.strip() == "":
        return "–•–æ–ª–∞—Ç–∏ –Ω–æ–º–∞—ä–ª—É–º"

    s = _prenorm(status).strip().lower()
    s = re.sub(r"[^\w\s]", " ", s)
    s = re.sub(r"\s+", " ", s).strip()

    # –ò–∫–æ–Ω–∫–∏/—è—Ä–ª—ã–∫–∏
    if any(tok in s for tok in ["‚úÖ", "üü¢", "green", "ok"]):
        return "–Ø—Ä–æ–∫–ª–∏"
    if any(tok in s for tok in ["‚õî", "üõë", "üî¥", "‚ùå"]):
        return "–Ø—Ä–æ–∫—Å–∏–∑"
    if any(tok in s for tok in ["üõ†", "üü°", "‚ö†"]):
        return "–¢–∞—ä–º–∏—Ä—Ç–∞–ª–∞–±"

    # –†–∞–±–æ—Ç–∞–µ—Ç
    if (
        "—è—Ä–æ“õ–ª–∏" in s or "—è—Ä–æ–∫–ª–∏" in s
        or "–∏—à–ª–∞–π–¥–∏" in s or "–∏—à–ª–∞–º–æ“õ–¥–∞" in s or "–∏—à–ª–∞–± —Ç—É—Ä–∏–±–¥–∏" in s
        or "–∏—à–≥–∞ —è—Ä–æ“õ–ª–∏" in s or "–∏—à–≥–∞ —è—Ä–æ–∫–ª–∏" in s
        or "—ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏—è–¥–∞" in s or "—Ñ–æ–π–¥–∞–ª–∞–Ω–∏—à–¥–∞" in s or "–≤ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏" in s
        or "operational" in s or "in service" in s or "working" in s
        or re.search(r"\b–≤\s*—Ä–∞–±–æ—á(–µ–º|–µ–µ)?\s*—Å–æ—Å—Ç–æ—è–Ω–∏(–∏|–µ)\b", s)
        or "–∏—Å–ø—Ä–∞–≤–µ–Ω" in s or "–∏—Å–ø—Ä–∞–≤–Ω–∞" in s or "–∏—Å–ø—Ä–∞–≤–Ω–æ" in s or "–∏—Å–ø—Ä–∞–≤–Ω—ã–π" in s
        or "—Ä–∞–±–æ—Ç–∞–µ—Ç" in s or "ready" in s or "good" in s or "active" in s
    ):
        return "–Ø—Ä–æ–∫–ª–∏"

    # –ù–µ —Ä–∞–±–æ—Ç–∞–µ—Ç
    if (
        "—è—Ä–æ“õ—Å–∏–∑" in s or "—è—Ä–æ–∫—Å–∏–∑" in s
        or "–∏—à–ª–∞–º–∞—è–ø—Ç–∏" in s or "–∏—à–ª–∞–º–∞–π–¥–∏" in s or "–∏—à–ª–∞–º–∞–≥–∞–Ω" in s
        or "–∏—à–¥–∞–Ω —á–∏“õ“õ–∞–Ω" in s or "–∏—à–¥–∞–Ω —á–∏–∫–∫–∞–Ω" in s or "—Ç–∏–∑–∏–º–¥–∞–Ω —Ç–∞—à“õ–∞—Ä–∏" in s
        or "–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç" in s or "–≤ –Ω–µ –∏—Å–ø—Ä–∞–≤–Ω" in s or "–≤–Ω–µ –∏—Å–ø—Ä–∞–≤–Ω" in s
        or "broken" in s or "inactive" in s or "out of order" in s
        or "“õ–∏—Å–º–∞–Ω –∏—à–ª–∞–º–∞–π–¥–∏" in s or "—á–∞—Å—Ç–∏—á–Ω–æ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç" in s
        or ("–∏—Å–ø—Ä–∞–≤–µ–Ω" in s and "–Ω–µ" in s)
        or "–Ω–µ–∏—Å–ø—Ä–∞–≤" in s
    ):
        return "–Ø—Ä–æ–∫—Å–∏–∑"

    # –†–µ–º–æ–Ω—Ç/–æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ
    if (
        "—Ç–∞—ä–º–∏—Ä—Ç–∞–ª–∞–±" in s or "—Ç–∞–º–∏—Ä—Ç–∞–ª–∞–±" in s
        or "—Ç–∞—ä–º–∏—Ä–¥–∞" in s or "—Ä–µ–º–æ–Ω—Ç–¥–∞" in s
        or "—Ä–µ–º–æ–Ω—Ç" in s or "—Ä–µ–º–æ–Ω—Ç–∏—Ä—É–µ—Ç—Å—è" in s
        or "–Ω–∞ —Ä–µ–º–æ–Ω—Ç–µ" in s or re.search(r"\b–≤\s*—Ä–µ–º–æ–Ω—Ç–Ω", s)
        or "–æ–±—Å–ª—É–∂–∏–≤–∞–Ω" in s or "—Ç–µ—Ö–æ–±—Å–ª—É–∂" in s
        or "maintenance" in s or "under repair" in s or "repair" in s
    ):
        return "–¢–∞—ä–º–∏—Ä—Ç–∞–ª–∞–±"

    return "–•–æ–ª–∞—Ç–∏ –Ω–æ–º–∞—ä–ª—É–º"


def get_status_emoji(status: str) -> str:
    mapping = {
        "–Ø—Ä–æ–∫–ª–∏": "üü©",
        "–¢–∞—ä–º–∏—Ä—Ç–∞–ª–∞–±": "üü®",
        "–Ø—Ä–æ–∫—Å–∏–∑": "üü•",
    }
    return mapping.get(status, "")


# ---- –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–∞ GPS (—Ç—Ä–µ–∫–µ—Ä–∞) ----
def normalize_tracker_flag(value) -> bool:
    if value is None:
        return False

    s = str(value).strip()
    if s == "":
        return False

    try:
        num = float(s.replace(",", "."))
        if num > 0:
            return True
        if num == 0:
            return False
    except ValueError:
        pass

    s_low = s.lower()

    if "–º–∞–≤–∂—É–¥ —ç–º–∞—Å" in s_low or "mavjud emas" in s_low:
        return False

    if "–º–∞–≤–∂—É–¥" in s_low or "mavjud" in s_low:
        return True

    if s_low in ["no", "–Ω–µ—Ç", "yo'q", "–π—û“õ", "yuk", "–π—É–∫", "0", "false", "n"]:
        return False

    if s_low in ["yes", "–¥–∞", "ha", "bor", "–µ—Å—Ç—å", "1", "true", "y", "–¥"]:
        return True

    if "gps" in s_low or "—Ç—Ä–µ–∫–µ—Ä" in s_low:
        if "–Ω–µ—Ç" not in s_low and "yo'q" not in s_low and "–π—û“õ" not in s_low:
            return True

    return False


# ---------- –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ (async) ----------
async def async_safe_api_call():
    global LAST_API_CALL
    now = datetime.now()
    elapsed = (now - LAST_API_CALL).total_seconds()
    if elapsed < API_DELAY:
        await asyncio.sleep((API_DELAY - elapsed) + random.uniform(0, 0.4))
    LAST_API_CALL = datetime.now()


# ---------- –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–≥–∏–æ–Ω–∞ (–¥–ª—è to_thread) ----------
def load_single_region_sync(region_sheet: Tuple[str, str]) -> Tuple[str, pd.DataFrame]:
    region_name, sheet_id = region_sheet
    if not sheet_id:
        logger.warning(f"–ù–µ—Ç sheet_id –¥–ª—è —Ä–µ–≥–∏–æ–Ω–∞ {region_name}")
        return region_name, pd.DataFrame()

    try:
        sh = gc.open_by_key(sheet_id)
        ws = sh.sheet1
        values = ws.get_all_records()
        df = pd.DataFrame(values)

        if df.empty:
            logger.info(f"–†–µ–≥–∏–æ–Ω {region_name}: —Ç–∞–±–ª–∏—Ü–∞ –ø—É—Å—Ç–∞—è")
            return region_name, pd.DataFrame()

        df.columns = [str(c).strip() for c in df.columns]

        status_col = find_column(df, STATUS_ALIASES)
        type_col   = find_column(df, TYPE_ALIASES)
        region_col = find_column(df, REGION_ALIASES)

        if status_col:
            raw_vc = df[status_col].astype(str).str.strip().replace("", "‚àÖ").value_counts().head(15)
            logger.info(f"üîé {region_name}: TOP —Å—Ç–∞—Ç—É—Å–æ–≤ (raw): {raw_vc.to_dict()}")

        qty_col = find_column(df, QTY_ALIASES)
        if qty_col:
            df["qty"] = pd.to_numeric(df[qty_col], errors="coerce").fillna(0).astype(int)
            df.loc[df["qty"] <= 0, "qty"] = 1
        else:
            df["qty"] = 1

        df["region_name"] = region_name

        if type_col:
            df["type_normalized"] = df[type_col].apply(normalize_tech_type)
            before = len(df)
            df = df[df["type_normalized"].notna() & (df["type_normalized"] != "")]
            after = len(df)
            if before != after:
                logger.info(f"üìù {region_name}: –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {before - after} —Å—Ç—Ä–æ–∫ —Å –ø—É—Å—Ç—ã–º–∏/—Å–ª—É–∂–µ–±–Ω—ã–º–∏ —Ç–∏–ø–∞–º–∏")
        else:
            logger.warning(f"‚ö†Ô∏è {region_name}: –∫–æ–ª–æ–Ω–∫–∞ —Ç–∏–ø–∞ —Ç–µ—Ö–Ω–∏–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return region_name, pd.DataFrame()

        if status_col:
            df[status_col] = df[status_col].fillna("")
            df["status_normalized"] = df[status_col].apply(normalize_status)
            logger.info(f"üîç {region_name}: –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç–∞—Ç—É—Å—ã: {df['status_normalized'].value_counts().to_dict()}")
        else:
            df["status_normalized"] = "–•–æ–ª–∞—Ç–∏ –Ω–æ–º–∞—ä–ª—É–º"
            logger.warning(f"‚ö†Ô∏è {region_name}: –∫–æ–ª–æ–Ω–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

        if region_col:
            df["city_district"] = df[region_col].fillna("–ù–µ —É–∫–∞–∑–∞–Ω")
            df["city_district"] = df["city_district"].apply(
                lambda x: region_name if x == "–ù–µ —É–∫–∞–∑–∞–Ω" or str(x).strip() == "" else str(x).strip()
            )
        else:
            df["city_district"] = region_name
            logger.warning(f"‚ÑπÔ∏è {region_name}: –∫–æ–ª–æ–Ω–∫–∞ –≥–æ—Ä–æ–¥–∞/—Ä–∞–π–æ–Ω–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

        tracker_col = find_column(df, TRACKER_ALIASES)
        if tracker_col:
            df["has_tracker"] = df[tracker_col].apply(normalize_tracker_flag)
        else:
            df["has_tracker"] = False

        keep = ["region_name", "city_district", "type_normalized", "status_normalized", "qty", "has_tracker"]
        df = df[keep]

        total_qty = int(df["qty"].sum())
        status_stats = df.groupby("status_normalized")["qty"].sum()
        logger.info(
            "‚úì %s: %s —Å—Ç—Ä–æ–∫, %s –µ–¥. [%s]",
            region_name,
            len(df),
            total_qty,
            ", ".join([f"{k}: {int(v)}" for k, v in status_stats.items()])
        )
        return region_name, df

    except Exception as e:
        if "429" in str(e):
            logger.warning(f"‚è≥ –õ–∏–º–∏—Ç API –¥–ª—è {region_name}, –∂–¥—É 10 —Å–µ–∫—É–Ω–¥ (–≤ –ø–æ—Ç–æ–∫–µ)...")
            time.sleep(10)
            try:
                sh = gc.open_by_key(sheet_id)
                ws = sh.sheet1
                values = ws.get_all_records()
                df = pd.DataFrame(values)
                if df.empty:
                    return region_name, pd.DataFrame()

                df.columns = [str(c).strip() for c in df.columns]
                status_col = find_column(df, STATUS_ALIASES)
                type_col   = find_column(df, TYPE_ALIASES)
                region_col = find_column(df, REGION_ALIASES)

                qty_col = find_column(df, QTY_ALIASES)
                if qty_col:
                    df["qty"] = pd.to_numeric(df[qty_col], errors="coerce").fillna(0).astype(int)
                    df.loc[df["qty"] <= 0, "qty"] = 1
                else:
                    df["qty"] = 1

                df["region_name"] = region_name

                if type_col:
                    df["type_normalized"] = df[type_col].apply(normalize_tech_type)
                    df = df[df["type_normalized"].notna() & (df["type_normalized"] != "")]
                else:
                    return region_name, pd.DataFrame()

                if status_col:
                    df[status_col] = df[status_col].fillna("")
                    df["status_normalized"] = df[status_col].apply(normalize_status)
                else:
                    df["status_normalized"] = "–•–æ–ª–∞—Ç–∏ –Ω–æ–º–∞—ä–ª—É–º"

                if region_col:
                    df["city_district"] = df[region_col].fillna("–ù–µ —É–∫–∞–∑–∞–Ω")
                    df["city_district"] = df["city_district"].apply(
                        lambda x: region_name if x == "–ù–µ —É–∫–∞–∑–∞–Ω" or str(x).strip() == "" else str(x).strip()
                    )
                else:
                    df["city_district"] = region_name

                tracker_col = find_column(df, TRACKER_ALIASES)
                if tracker_col:
                    df["has_tracker"] = df[tracker_col].apply(normalize_tracker_flag)
                else:
                    df["has_tracker"] = False

                df = df[["region_name", "city_district", "type_normalized", "status_normalized", "qty", "has_tracker"]]
                logger.info(f"‚úì {region_name}: –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —É—Å–ø–µ—à–Ω–∞")
                return region_name, df

            except Exception as retry_error:
                logger.error(f"‚úó {region_name}: –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–µ - {retry_error}")
                return region_name, pd.DataFrame()
        else:
            logger.error(f"‚úó {region_name}: –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ - {e}")
            return region_name, pd.DataFrame()


# ---------- –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ –æ–±—ë—Ä—Ç–∫–∏ ----------
sem = asyncio.Semaphore(PARALLEL_LIMIT)


async def load_single_region_async(region_sheet: Tuple[str, str]) -> Tuple[str, pd.DataFrame]:
    async with sem:
        await async_safe_api_call()
        return await asyncio.to_thread(load_single_region_sync, region_sheet)


async def load_all_regions_async() -> pd.DataFrame:
    regions = [(name, sid) for name, sid in REGION_SHEETS.items() if sid]
    if not regions:
        return pd.DataFrame(columns=["region_name", "city_district", "type_normalized", "status_normalized", "qty", "has_tracker"])

    tasks = [load_single_region_async(rs) for rs in regions]
    results = await asyncio.gather(*tasks, return_exceptions=True)

    parts: List[pd.DataFrame] = []
    ok = 0
    for r in results:
        if isinstance(r, Exception):
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ä–µ–≥–∏–æ–Ω–∞: {r}")
            continue
        name, df = r
        if not df.empty:
            parts.append(df)
            ok += 1
        else:
            logger.warning(f"‚ùå {name}: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")

    if parts:
        df = pd.concat(parts, ignore_index=True)
        total_qty = int(df["qty"].sum())
        logger.info(f"üìä –ò–¢–û–ì–û: {len(df)} —Å—Ç—Ä–æ–∫, {total_qty} –µ–¥. –∏–∑ {ok} —Ä–µ–≥–∏–æ–Ω–æ–≤")
        return df

    logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∏ –∏–∑ –æ–¥–Ω–æ–≥–æ —Ä–µ–≥–∏–æ–Ω–∞")
    return pd.DataFrame(columns=["region_name", "city_district", "type_normalized", "status_normalized", "qty", "has_tracker"])


# ---- –ö–µ—à (async) ----
async def get_df_async(region: Optional[str] = None, force_refresh: bool = False) -> pd.DataFrame:
    key = region or "ALL"
    now = datetime.now()

    if not force_refresh and key in CACHE and now < CACHE[key][1]:
        return CACHE[key][0].copy()

    try:
        if region and region != "ALL":
            _, df = await load_single_region_async((region, REGION_SHEETS.get(region)))
        else:
            df = await load_all_regions_async()

        CACHE[key] = (df.copy(), now + CACHE_TTL)
        return df
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ get_df_async: {e}")
        if key in CACHE:
            return CACHE[key][0].copy()
        return pd.DataFrame(columns=["region_name", "city_district", "type_normalized", "status_normalized", "qty", "has_tracker"])


# ---- –ê–≥—Ä–µ–≥–∞—Ç—ã –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ ----
def count_type_per_region(df_all: pd.DataFrame, tech_type: str) -> pd.DataFrame:
    if df_all.empty:
        return pd.DataFrame(columns=["region_name", "qty"])
    try:
        normalized_type = normalize_tech_type(tech_type)
        if not normalized_type:
            return pd.DataFrame(columns=["region_name", "qty"])
        sub = df_all.loc[df_all["type_normalized"] == normalized_type].copy()
        if sub.empty:
            return pd.DataFrame(columns=["region_name", "qty"])
        return (
            sub
            .groupby("region_name", as_index=False)
            .agg(qty=("qty", "sum"))
            .sort_values("qty", ascending=False)
        )
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ count_type_per_region: {e}")
        return pd.DataFrame(columns=["region_name", "qty"])


def get_status_distribution_for_type_region(df_all: pd.DataFrame, tech_type: str, region: str) -> pd.DataFrame:
    if df_all.empty:
        return pd.DataFrame(columns=["status_normalized", "qty"])
    try:
        normalized_type = normalize_tech_type(tech_type)
        if not normalized_type:
            return pd.DataFrame(columns=["status_normalized", "qty"])
        mask = (df_all["region_name"] == region) & (df_all["type_normalized"] == normalized_type)
        filtered = df_all.loc[mask].copy()
        if filtered.empty:
            return pd.DataFrame(columns=["status_normalized", "qty"])
        return (
            filtered
            .groupby("status_normalized", as_index=False)
            .agg(qty=("qty", "sum"))
            .sort_values("qty", ascending=False)
        )
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ get_status_distribution_for_type_region: {e}")
        return pd.DataFrame(columns=["status_normalized", "qty"])


def get_detailed_city_status(df_all: pd.DataFrame, tech_type: str, region: str) -> Dict[str, Dict[str, int]]:
    if df_all.empty:
        return {}
    try:
        normalized_type = normalize_tech_type(tech_type)
        if not normalized_type:
            return {}
        mask = (df_all["region_name"] == region) & (df_all["type_normalized"] == normalized_type)
        filtered = df_all.loc[mask].copy()
        if filtered.empty:
            return {}
        city_status: Dict[str, Dict[str, int]] = {}
        for city in filtered["city_district"].unique():
            city_data = filtered[filtered["city_district"] == city]
            status_counts: Dict[str, int] = {}
            for st in ["–Ø—Ä–æ–∫–ª–∏", "–Ø—Ä–æ–∫—Å–∏–∑", "–¢–∞—ä–º–∏—Ä—Ç–∞–ª–∞–±", "–•–æ–ª–∞—Ç–∏ –Ω–æ–º–∞—ä–ª—É–º"]:
                cnt = int(city_data.loc[city_data["status_normalized"] == st, "qty"].sum())
                if cnt > 0:
                    status_counts[st] = cnt
            total_city = sum(status_counts.values())
            if total_city > 0:
                city_status[str(city) if str(city).strip() else "–ù–µ —É–∫–∞–∑–∞–Ω"] = status_counts
        return city_status
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ get_detailed_city_status: {e}")
        return {}


def all_types_summary(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty:
        return pd.DataFrame(columns=[COL_TYPE, "qty"])
    try:
        valid = df[df["type_normalized"].notna()].copy()
        if valid.empty:
            return pd.DataFrame(columns=[COL_TYPE, "qty"])
        return (
            valid
            .groupby("type_normalized", as_index=False)
            .agg(qty=("qty", "sum"))
            .sort_values("qty", ascending=False)
            .rename(columns={"type_normalized": COL_TYPE})
        )
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ all_types_summary: {e}")
        return pd.DataFrame(columns=[COL_TYPE, "qty"])


def get_region_counts(df_all: pd.DataFrame) -> Dict[str, int]:
    if df_all.empty:
        return {region: 0 for region in REGION_SHEETS.keys()}
    try:
        valid = df_all[df_all["type_normalized"].notna()].copy()
        stats = valid.groupby("region_name", as_index=False).agg(qty=("qty", "sum"))
        as_dict = dict(zip(stats["region_name"], stats["qty"]))
        return {region: int(as_dict.get(region, 0)) for region in REGION_SHEETS.keys()}
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ get_region_counts: {e}")
        return {region: 0 for region in REGION_SHEETS.keys()}


def create_regions_keyboard(df_all: pd.DataFrame) -> types.InlineKeyboardMarkup:
    try:
        region_counts = get_region_counts(df_all)
        total = int(df_all[df_all["type_normalized"].notna()]["qty"].sum()) if not df_all.empty else 0
        kb = InlineKeyboardBuilder()
        for region in REGION_SHEETS.keys():
            kb.button(text=f"{region} ({region_counts.get(region, 0)} –µ–¥.)", callback_data=f"region:{region}")
        kb.button(text=f"–í—Å–µ –æ–±–ª–∞—Å—Ç–∏ ({total} –µ–¥.)", callback_data="region:ALL")
        kb.adjust(2)
        return kb.as_markup()
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã –æ–±–ª–∞—Å—Ç–µ–π: {e}")
        kb = InlineKeyboardBuilder()
        for region in REGION_SHEETS.keys():
            kb.button(text=region, callback_data=f"region:{region}")
        kb.button(text="–í—Å–µ –æ–±–ª–∞—Å—Ç–∏", callback_data="region:ALL")
        kb.adjust(2)
        return kb.as_markup()


def create_types_keyboard(types_df: pd.DataFrame) -> Tuple[types.InlineKeyboardMarkup, int]:
    kb = InlineKeyboardBuilder()
    valid_types = 0
    for _, row in types_df.iterrows():
        tech_type = row[COL_TYPE]
        count = int(row["qty"])
        if tech_type and str(tech_type).strip() and str(tech_type).strip().lower() != "nan":
            payload = f"count_type:{tech_type}"
            cbid = put_cb(payload)
            kb.button(text=f"{tech_type} ({count} –µ–¥.)", callback_data=cbid)
            valid_types += 1
    kb.button(text="‚Ü©Ô∏è –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="main_menu")
    kb.adjust(1)
    return kb.as_markup(), valid_types


def summarize_overall_status(status_df: pd.DataFrame) -> str:
    counts = {"–Ø—Ä–æ–∫–ª–∏": 0, "–¢–∞—ä–º–∏—Ä—Ç–∞–ª–∞–±": 0, "–Ø—Ä–æ–∫—Å–∏–∑": 0, "–•–æ–ª–∞—Ç–∏ –Ω–æ–º–∞—ä–ª—É–º": 0}
    if not status_df.empty:
        for _, row in status_df.iterrows():
            st = str(row["status_normalized"])
            qty = int(row["qty"])
            if st in counts:
                counts[st] = qty
    return f"üü© {counts['–Ø—Ä–æ–∫–ª–∏']} | üü® {counts['–¢–∞—ä–º–∏—Ä—Ç–∞–ª–∞–±']} | üü• {counts['–Ø—Ä–æ–∫—Å–∏–∑']}"


def fmt_status_distribution(status_df: pd.DataFrame) -> str:
    if status_df.empty:
        return "‚öôÔ∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ —Å–æ—Å—Ç–æ—è–Ω–∏—è—Ö —Ç–µ—Ö–Ω–∏–∫–∏"
    lines: List[str] = []
    total = 0
    for _, row in status_df.iterrows():
        status = row["status_normalized"]
        qty = int(row["qty"])
        total += qty
        emoji = get_status_emoji(status)
        if emoji:
            lines.append(f"{emoji} <b>{esc(status)}</b> ‚Äî {qty} –µ–¥.")
        else:
            lines.append(f"<b>{esc(status)}</b> ‚Äî {qty} –µ–¥.")
    lines.append(f"\n<b>üìä –í—Å–µ–≥–æ:</b> {total} –µ–¥.")
    return "\n".join(lines)


def fmt_detailed_city_status(city_status_data: Dict[str, Dict[str, int]]) -> str:
    if not city_status_data:
        return "üèôÔ∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –≥–æ—Ä–æ–¥–∞–º/—Ä–∞–π–æ–Ω–∞–º"

    rows = []
    for city, cnt in city_status_data.items():
        g = int(cnt.get("–Ø—Ä–æ–∫–ª–∏", 0))
        y = int(cnt.get("–¢–∞—ä–º–∏—Ä—Ç–∞–ª–∞–±", 0))
        r = int(cnt.get("–Ø—Ä–æ–∫—Å–∏–∑", 0))
        k = int(cnt.get("–•–æ–ª–∞—Ç–∏ –Ω–æ–º–∞—ä–ª—É–º", 0))
        total = g + y + r + k
        rows.append((city, total, g, y, r, k))

    rows.sort(key=lambda t: (-t[4], -t[3], t[0].lower()))
    lines: List[str] = []
    for city, total, g, y, r, k in rows:
        parts: List[str] = []
        if g > 0:
            parts.append(f"üü© {g}")
        if y > 0:
            parts.append(f"üü® {y}")
        if r > 0:
            parts.append(f"üü• {r}")
        status_line = " | ".join(parts) if parts else "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
        lines.append(
            f"üìç <b>{esc(city)}</b> ‚Äî {total} –µ–¥.\n"
            f"{status_line}"
        )
    return "\n\n".join(lines)


def fmt_table(df: pd.DataFrame, left_col: str, max_lines: int = 100) -> str:
    if df.empty:
        return "üì≠ –î–∞–Ω–Ω—ã—Ö –Ω–µ—Ç"

    lines: List[str] = []
    for _, row in df.iterrows():
        value = row.get(left_col)
        if pd.isna(value) or str(value).strip() == "":
            value = "–ù–µ —É–∫–∞–∑–∞–Ω–æ"
        qty = int(row.get("qty", 0))
        lines.append(f"‚Ä¢ {esc(value)} ‚Äî {qty} –µ–¥.")

    if len(lines) > max_lines:
        tail = len(lines) - max_lines
        lines = lines[:max_lines] + [f"‚Ä¶ –∏ –µ—â—ë {tail} —Å—Ç—Ä–æ–∫"]

    return "\n".join(lines)


def fmt_types_with_statuses(df_subset: pd.DataFrame, max_types: int = 50) -> str:
    if df_subset.empty or "type_normalized" not in df_subset.columns:
        return "üì≠ –î–∞–Ω–Ω—ã—Ö –æ —Ç–∏–ø–∞—Ö —Ç–µ—Ö–Ω–∏–∫–∏ –Ω–µ—Ç"

    try:
        agg = (
            df_subset
            .groupby(["type_normalized", "status_normalized"], as_index=False)
            .agg(qty=("qty", "sum"))
        )

        totals = (
            agg
            .groupby("type_normalized", as_index=False)
            .agg(total=("qty", "sum"))
            .sort_values("total", ascending=False)
        )

        lines: List[str] = []
        shown = 0

        for _, row in totals.iterrows():
            t = row["type_normalized"]
            if pd.isna(t) or str(t).strip() == "":
                t = "–ù–µ —É–∫–∞–∑–∞–Ω–æ"

            t_rows = agg[agg["type_normalized"] == row["type_normalized"]]

            g = y = r = k = 0
            for _, tr in t_rows.iterrows():
                st = tr["status_normalized"]
                q = int(tr["qty"])
                if st == "–Ø—Ä–æ–∫–ª–∏":
                    g += q
                elif st == "–¢–∞—ä–º–∏—Ä—Ç–∞–ª–∞–±":
                    y += q
                elif st == "–Ø—Ä–æ–∫—Å–∏–∑":
                    r += q
                else:
                    k += q

            parts: List[str] = []
            if g > 0:
                parts.append(f"üü© {g}")
            if y > 0:
                parts.append(f"üü® {y}")
            if r > 0:
                parts.append(f"üü• {r}")
            if k > 0:
                parts.append(f"‚¨õ {k}")

            status_line = " | ".join(parts) if parts else "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"

            lines.append(
                f"‚Ä¢ <b>{esc(t)}</b> ‚Äî {int(row['total'])} –µ–¥.\n"
                f"   {status_line}"
            )

            shown += 1
            if shown >= max_types:
                if len(totals) > max_types:
                    lines.append(f"‚Ä¶ –∏ –µ—â—ë {len(totals) - max_types} —Ç–∏–ø–æ–≤")
                break

        return "\n".join(lines) if lines else "üì≠ –î–∞–Ω–Ω—ã—Ö –æ —Ç–∏–ø–∞—Ö —Ç–µ—Ö–Ω–∏–∫–∏ –Ω–µ—Ç"
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ fmt_types_with_statuses: {e}")
        return "‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ —Ç–∏–ø–æ–≤"


# ---- –ö–∞—Ç–µ–≥–æ—Ä–∏–∏: –∞–≤—Ç–æ—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç / –ø—Ä–æ—á–µ–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ ----
def is_equipment_type(type_name: str) -> bool:
    """
    True, –µ—Å–ª–∏ —Ç–∏–ø –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –ø—Ä–∏—Ü–µ–ø–∞–º/—Ü–∏—Å—Ç–µ—Ä–Ω–∞–º/–Ω–∞—Å–æ—Å–∞–º/–∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä–∞–º/–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞–º –∏ —Ç.–ø.
    –ü–æ —Ç–≤–æ–µ–º—É –æ–ø–∏—Å–∞–Ω–∏—é –¥–ª—è –ê–Ω–¥–∏–∂–∞–Ω–∞:
      '–ø—Ä–∏—Ü–µ–ø', '–°–ê–ö', '—Ü–∏—Å—Ç–µ—Ä–Ω–∞', '–∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä', '–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä' ‚Äî –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ.
    –†–∞—Å—à–∏—Ä–∏–º —ç—Ç–æ –ø—Ä–∞–≤–∏–ª–æ –∏ –¥–ª—è –¥—Ä—É–≥–∏—Ö –æ–±–ª–∞—Å—Ç–µ–π.
    """
    if not isinstance(type_name, str):
        return False
    s = type_name.lower()

    equipment_keywords = [
        "–ø—Ä–∏—Ü–µ–ø",
        "—Å–∞–∫",           # –°–ê–ö ‚Äî —Å—á–∏—Ç–∞–µ–º –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ–º
        "—Ü–∏—Å—Ç–µ—Ä–Ω",
        "–Ω–∞—Å–æ—Å",
        "–∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä",
        "–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä",
        "–∞–≥—Ä–µ–≥–∞—Ç",
        "–º–æ—Ç–æ–ø–æ–º–ø",
        "–Ω–∞—Å–æ—Å–Ω–∞—è",
        "–Ω–∞—Å–æ—Å —Å—Ç–∞–Ω—Ü",
    ]
    return any(k in s for k in equipment_keywords)


def summarize_region_categories(df_region: pd.DataFrame) -> Tuple[int, int, int]:
    if df_region.empty:
        return 0, 0, 0

    types = df_region["type_normalized"].astype(str)
    mask_equipment = types.apply(is_equipment_type)

    auto_qty = int(df_region.loc[~mask_equipment, "qty"].sum())
    equip_qty = int(df_region.loc[mask_equipment, "qty"].sum())
    total = auto_qty + equip_qty
    return auto_qty, equip_qty, total


def summarize_district_categories(df_region: pd.DataFrame, district: str) -> Tuple[int, int, int]:
    sub = df_region[df_region["city_district"] == district]
    if sub.empty:
        return 0, 0, 0

    types = sub["type_normalized"].astype(str)
    mask_equipment = types.apply(is_equipment_type)

    auto_qty = int(sub.loc[~mask_equipment, "qty"].sum())
    equip_qty = int(sub.loc[mask_equipment, "qty"].sum())
    total = auto_qty + equip_qty
    return auto_qty, equip_qty, total


def summarize_republic_categories(df_all: pd.DataFrame) -> Tuple[int, int, int]:
    if df_all.empty or "type_normalized" not in df_all.columns:
        return 0, 0, 0

    types = df_all["type_normalized"].astype(str)
    mask_equipment = types.apply(is_equipment_type)

    auto_qty = int(df_all.loc[~mask_equipment, "qty"].sum())
    equip_qty = int(df_all.loc[mask_equipment, "qty"].sum())
    total = auto_qty + equip_qty
    return auto_qty, equip_qty, total


def get_status_distribution_any(df_subset: pd.DataFrame) -> pd.DataFrame:
    if df_subset.empty or "status_normalized" not in df_subset.columns:
        return pd.DataFrame(columns=["status_normalized", "qty"])
    try:
        return (
            df_subset
            .groupby("status_normalized", as_index=False)
            .agg(qty=("qty", "sum"))
            .sort_values("qty", ascending=False)
        )
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ get_status_distribution_any: {e}")
        return pd.DataFrame(columns=["status_normalized", "qty"])


def create_districts_keyboard(df_region: pd.DataFrame, region: str) -> types.InlineKeyboardMarkup:
    kb = InlineKeyboardBuilder()

    if not df_region.empty:
        dist_df = (
            df_region
            .groupby("city_district", as_index=False)
            .agg(qty=("qty", "sum"))
            .sort_values("qty", ascending=False)
        )
        for _, row in dist_df.iterrows():
            city = str(row["city_district"]) if str(row["city_district"]).strip() else "–ù–µ —É–∫–∞–∑–∞–Ω"
            qty = int(row["qty"])
            payload = f"district:{region}|{city}"
            cbid = put_cb(payload)
            kb.button(text=f"{city} ({qty} –µ–¥.)", callback_data=cbid)

    kb.button(text="‚Ü©Ô∏è –ù–∞–∑–∞–¥ –∫ –æ–±–ª–∞—Å—Ç—è–º", callback_data="back_to_regions")
    kb.adjust(2, 1)
    return kb.as_markup()


# ---- GPS-—É—á—ë—Ç –ø–æ –æ–±–ª–∞—Å—Ç—è–º ----
def count_trackers_by_region(df_all: pd.DataFrame) -> pd.DataFrame:
    if df_all.empty or "has_tracker" not in df_all.columns:
        return pd.DataFrame(columns=["region_name", "qty"])
    try:
        sub = df_all[df_all["has_tracker"]]
        if sub.empty:
            return pd.DataFrame(columns=["region_name", "qty"])
        return (
            sub
            .groupby("region_name", as_index=False)
            .agg(qty=("qty", "sum"))
            .sort_values("qty", ascending=False)
        )
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ count_trackers_by_region: {e}")
        return pd.DataFrame(columns=["region_name", "qty"])


async def safe_edit_message(message: types.Message, text: str, **kwargs) -> None:
    try:
        await message.edit_text(text, **kwargs)
    except TelegramBadRequest as e:
        if "message is too long" in str(e):
            parts = [text[i:i+4000] for i in range(0, len(text), 4000)]
            await message.edit_text(parts[0], **kwargs)
            for part in parts[1:]:
                await message.answer(part)
        else:
            raise e


def main_menu_kb() -> types.ReplyKeyboardMarkup:
    kb = ReplyKeyboardBuilder()
    buttons = [
        "üìç –û–±–ª–∞—Å—Ç–∏",
        "üìä –û–±—â–µ–µ –ø–æ —Ä–µ—Å–ø—É–±–ª–∏–∫–µ",
        "üîé –ü–æ—Å—á–∏—Ç–∞—Ç—å –ø–æ —Ç–∏–ø—É",
        "üì° GPS-—É—á—ë—Ç –ø–æ –æ–±–ª–∞—Å—Ç—è–º",
        "üîÑ –û–±–Ω–æ–≤–∏—Ç—å –∫–µ—à",
        "‚ÑπÔ∏è –ü–æ–º–æ—â—å",
    ]
    for txt in buttons:
        kb.button(text=txt)
    kb.adjust(2)
    return kb.as_markup(resize_keyboard=True)


# ---- Rate Limit middleware (–∑–∞—â–∏—Ç–∞ –æ—Ç —Å–ø–∞–º–∞) ----
class RateLimitMiddleware(BaseMiddleware):
    def __init__(self, limit: int = 5, per: float = 1.0):
        super().__init__()
        self.limit = limit
        self.per = per
        self._users = defaultdict(list)

    async def __call__(self, handler, event, data):
        from_user = getattr(event, "from_user", None)
        if not from_user:
            return await handler(event, data)

        user_id = from_user.id
        now = time.monotonic()

        timestamps = self._users[user_id]
        while timestamps and now - timestamps[0] > self.per:
            timestamps.pop(0)

        if len(timestamps) >= self.limit:
            # –º–æ–∂–Ω–æ –ø–æ –∂–µ–ª–∞–Ω–∏—é –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ
            return

        timestamps.append(now)
        return await handler(event, data)


# ---------- –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ ----------
async def main():
    bot = Bot(
        BOT_TOKEN,
        default=DefaultBotProperties(
            parse_mode=ParseMode.HTML,
            link_preview_is_disabled=False,
            protect_content=False
        )
    )
    dp = Dispatcher()

    # –∑–∞—â–∏—Ç–∞ –æ—Ç —Å–ø–∞–º–∞ –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    rate_mw = RateLimitMiddleware(limit=5, per=1.0)
    dp.message.middleware(rate_mw)
    dp.callback_query.middleware(rate_mw)

    @dp.message(Command("start"))
    async def start_cmd(m: types.Message):
        await m.answer(
            "ü§ñ <b>–ë–æ—Ç –¥–ª—è —É—á–µ—Ç–∞ —Ç–µ—Ö–Ω–∏–∫–∏</b>\n\n"
            "‚ú® <i>–î–µ—Ç–∞–ª—å–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ –æ–±–ª–∞—Å—Ç—è–º –∏ —Ä–∞–π–æ–Ω–∞–º</i>\n\n"
            "–ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é:\n"
            "‚Ä¢ <b>üìç –û–±–ª–∞—Å—Ç–∏</b> ‚Äî –≤—ã–±—Ä–∞—Ç—å –æ–±–ª–∞—Å—Ç—å –∏ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Å–≤–æ–¥–∫—É + —Ä–∞–π–æ–Ω—ã\n"
            "‚Ä¢ <b>üìä –û–±—â–µ–µ –ø–æ —Ä–µ—Å–ø—É–±–ª–∏–∫–µ</b> ‚Äî —Å–≤–æ–¥–∫–∞ –ø–æ –≤—Å–µ–º –æ–±–ª–∞—Å—Ç—è–º\n"
            "‚Ä¢ <b>üîé –ü–æ—Å—á–∏—Ç–∞—Ç—å –ø–æ —Ç–∏–ø—É</b> ‚Äî —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –æ–±–ª–∞—Å—Ç—è–º\n"
            "‚Ä¢ <b>üì° GPS-—É—á—ë—Ç –ø–æ –æ–±–ª–∞—Å—Ç—è–º</b> ‚Äî —Å–≤–æ–¥–∫–∞ –ø–æ –Ω–∞–ª–∏—á–∏—é GPS —É —Ç–µ—Ö–Ω–∏–∫–∏\n"
            "‚Ä¢ <b>üîÑ –û–±–Ω–æ–≤–∏—Ç—å –∫–µ—à</b> ‚Äî –æ–±–Ω–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ\n"
            "‚Ä¢ <b>‚ÑπÔ∏è –ü–æ–º–æ—â—å</b> ‚Äî –ø–æ–¥—Ä–æ–±–Ω–∞—è —Å–ø—Ä–∞–≤–∫–∞",
            reply_markup=main_menu_kb()
        )

    @dp.message(F.text == "‚ÑπÔ∏è –ü–æ–º–æ—â—å")
    async def help_cmd(m: types.Message):
        await m.answer(
            "üìñ <b>–ü–æ–¥—Ä–æ–±–Ω–∞—è —Å–ø—Ä–∞–≤–∫–∞</b>\n\n"
            "–≠—Ç–æ—Ç –±–æ—Ç –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —É—á—ë—Ç —Ç–µ—Ö–Ω–∏–∫–∏ –ø–æ –æ–±–ª–∞—Å—Ç—è–º/—Ä–∞–π–æ–Ω–∞–º —Å —Ä–∞–∑–±–∏–≤–∫–æ–π –ø–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è–º.\n\n"
            "üîò <b>–ö–Ω–æ–ø–∫–∏ –≥–ª–∞–≤–Ω–æ–≥–æ –º–µ–Ω—é</b>:\n"
            "‚Ä¢ <b>üìç –û–±–ª–∞—Å—Ç–∏</b>\n"
            "  1) –í—ã–±–∏—Ä–∞–µ—à—å –æ–±–ª–∞—Å—Ç—å.\n"
            "  2) –ë–æ—Ç –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç:\n"
            "     ‚Ä¢ –ê–≤—Ç–æ—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç / –ü—Ä–æ—á–∞—è —Ç–µ—Ö–Ω–∏–∫–∞ –∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ / –í—Å–µ–≥–æ\n"
            "     ‚Ä¢ –û—Ç–¥–µ–ª—å–Ω–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∞–≤—Ç–æ—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞ –∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è\n"
            "     ‚Ä¢ –°–ø–∏—Å–æ–∫ —Ç–∏–ø–æ–≤ —Ç–µ—Ö–Ω–∏–∫–∏ –≤ –æ–±–ª–∞—Å—Ç–∏\n"
            "     ‚Ä¢ –°–ø–∏—Å–æ–∫ —Ä–∞–π–æ–Ω–æ–≤ —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Ç–µ—Ö–Ω–∏–∫–∏.\n"
            "  3) –ü—Ä–∏ –≤—ã–±–æ—Ä–µ —Ä–∞–π–æ–Ω–∞ –±–æ—Ç –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –æ—Ç–¥–µ–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ:\n"
            "     ‚Ä¢ –ö–æ–ª-–≤–æ –∞–≤—Ç–æ—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞\n"
            "     ‚Ä¢ –ö–æ–ª-–≤–æ –ø—Ä–æ—á–µ–π —Ç–µ—Ö–Ω–∏–∫–∏\n"
            "     ‚Ä¢ –í—Å–µ–≥–æ\n"
            "     ‚Ä¢ –û–±—â–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ —Ä–∞–π–æ–Ω—É\n"
            "     ‚Ä¢ –¢–∏–ø—ã —Ç–µ—Ö–Ω–∏–∫–∏ –ø–æ —Ä–∞–π–æ–Ω—É —Å —Ä–∞–∑—Ä–µ–∑–æ–º –ø–æ —Å—Ç–∞—Ç—É—Å–∞–º.\n\n"
            "‚Ä¢ <b>üìä –û–±—â–µ–µ –ø–æ —Ä–µ—Å–ø—É–±–ª–∏–∫–µ</b>\n"
            "  –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∏—Ç–æ–≥–∏ –ø–æ —Ä–µ—Å–ø—É–±–ª–∏–∫–µ —Å –¥–µ–ª–µ–Ω–∏–µ–º –Ω–∞ –∞–≤—Ç–æ—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç –∏ –ø—Ä–æ—á—É—é —Ç–µ—Ö–Ω–∏–∫—É,\n"
            "  –∞ —Ç–∞–∫–∂–µ —Ä–∞–∑–¥–µ–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è–º.\n\n"
            "‚Ä¢ <b>üîé –ü–æ—Å—á–∏—Ç–∞—Ç—å –ø–æ —Ç–∏–ø—É</b>\n"
            "  –°–Ω–∞—á–∞–ª–∞ –≤—ã–±–∏—Ä–∞–µ—à—å —Ç–∏–ø, –∑–∞—Ç–µ–º –±–æ—Ç –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –æ–±–ª–∞—Å—Ç—è–º –∏ –¥–µ—Ç–∞–ª–∏.\n\n"
            "‚Ä¢ <b>üì° GPS-—É—á—ë—Ç –ø–æ –æ–±–ª–∞—Å—Ç—è–º</b>\n"
            "  –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —Å–∫–æ–ª—å–∫–æ —Ç–µ—Ö–Ω–∏–∫–∏ —Å GPS –µ—Å—Ç—å –≤ –∫–∞–∂–¥–æ–π –æ–±–ª–∞—Å—Ç–∏.\n\n"
            "‚Ä¢ <b>üîÑ –û–±–Ω–æ–≤–∏—Ç—å –∫–µ—à</b>\n"
            "  –û—á–∏—â–∞–µ—Ç –∫–µ—à –¥–∞–Ω–Ω—ã—Ö. –°–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—Ä–æ—Å –ø–æ–¥—Ç—è–Ω–µ—Ç —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ Google Sheets.\n"
        )

    @dp.message(F.text == "üìç –û–±–ª–∞—Å—Ç–∏")
    async def choose_region(m: types.Message):
        try:
            loading_msg = await m.answer("üîÑ –ó–∞–≥—Ä—É–∂–∞—é –¥–∞–Ω–Ω—ã–µ...")
            df_all = await get_df_async(None, force_refresh=False)
            kb = create_regions_keyboard(df_all)
            await loading_msg.delete()
            await m.answer("üìç –í—ã–±–µ—Ä–∏ –æ–±–ª–∞—Å—Ç—å:", reply_markup=kb)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ choose_region: {e}")
            await m.answer("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö")

    @dp.callback_query(F.data.startswith("region:"))
    async def show_region_summary(c: types.CallbackQuery):
        try:
            await c.answer("üìä –ó–∞–≥—Ä—É–∂–∞—é –¥–∞–Ω–Ω—ã–µ –ø–æ –æ–±–ª–∞—Å—Ç–∏...")
            region = c.data.split(":", 1)[1]

            # –í—Å–µ –æ–±–ª–∞—Å—Ç–∏
            if region == "ALL":
                df = await get_df_async(None, force_refresh=False)
                if df.empty:
                    await c.message.edit_text("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è")
                    return

                auto_qty, equip_qty, total = summarize_republic_categories(df)
                types_df = all_types_summary(df)

                if df.empty or "type_normalized" not in df.columns:
                    auto_df = pd.DataFrame(columns=df.columns)
                    equip_df = pd.DataFrame(columns=df.columns)
                else:
                    types = df["type_normalized"].astype(str)
                    mask_equipment = types.apply(is_equipment_type)
                    auto_df = df[~mask_equipment].copy()
                    equip_df = df[mask_equipment].copy()

                status_auto = get_status_distribution_any(auto_df)
                status_equip = get_status_distribution_any(equip_df)

                result = (
                    "üìä <b>–û–±—â–µ–µ –ø–æ —Ä–µ—Å–ø—É–±–ª–∏–∫–µ</b>\n\n"
                    f"üöó <b>–ê–≤—Ç–æ—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç:</b> {auto_qty} –µ–¥.\n"
                    f"‚öôÔ∏è <b>–ü—Ä–æ—á–∞—è —Ç–µ—Ö–Ω–∏–∫–∞ –∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ:</b> {equip_qty} –µ–¥.\n"
                    f"üìä <b>–í—Å–µ–≥–æ:</b> {total} –µ–¥.\n\n"
                    f"üìà <b>–°–æ—Å—Ç–æ—è–Ω–∏—è ‚Äî –∞–≤—Ç–æ—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç:</b>\n"
                    f"{fmt_status_distribution(status_auto)}\n\n"
                    f"üìà <b>–°–æ—Å—Ç–æ—è–Ω–∏—è ‚Äî –ø—Ä–æ—á–∞—è —Ç–µ—Ö–Ω–∏–∫–∞ –∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ:</b>\n"
                    f"{fmt_status_distribution(status_equip)}\n\n"
                )
                result += "üì≠ –î–∞–Ω–Ω—ã—Ö –Ω–µ—Ç" if types_df.empty else fmt_table(types_df, COL_TYPE)

                kb = InlineKeyboardBuilder()
                kb.button(text="‚Ü©Ô∏è –ù–∞–∑–∞–¥ –∫ –æ–±–ª–∞—Å—Ç—è–º", callback_data="back_to_regions")
                kb.adjust(1)
                await safe_edit_message(c.message, result, reply_markup=kb.as_markup())
                return

            # –ö–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –æ–±–ª–∞—Å—Ç—å
            df_region = await get_df_async(region, force_refresh=False)
            if df_region.empty:
                await c.message.edit_text("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏")
                return

            auto_qty, equip_qty, total = summarize_region_categories(df_region)

            # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –¥–ª—è —Å—Ç–∞—Ç—É—Å–æ–≤
            types_series = df_region["type_normalized"].astype(str)
            mask_equipment = types_series.apply(is_equipment_type)
            auto_df_region = df_region[~mask_equipment].copy()
            equip_df_region = df_region[mask_equipment].copy()

            status_auto_region = get_status_distribution_any(auto_df_region)
            status_equip_region = get_status_distribution_any(equip_df_region)

            types_df = all_types_summary(df_region)
            if types_df.empty:
                types_block = "\nüìã <b>–¢–∏–ø—ã —Ç–µ—Ö–Ω–∏–∫–∏ –≤ –æ–±–ª–∞—Å—Ç–∏:</b>\nüì≠ –î–∞–Ω–Ω—ã—Ö –æ —Ç–∏–ø–∞—Ö —Ç–µ—Ö–Ω–∏–∫–∏ –Ω–µ—Ç\n"
            else:
                types_block = "\nüìã <b>–¢–∏–ø—ã —Ç–µ—Ö–Ω–∏–∫–∏ –≤ –æ–±–ª–∞—Å—Ç–∏:</b>\n" + fmt_table(types_df, COL_TYPE) + "\n"

            text = (
                f"üìç <b>–û–±–ª–∞—Å—Ç—å:</b> {esc(region)}\n\n"
                f"üöó <b>–ê–≤—Ç–æ—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç:</b> {auto_qty} –µ–¥.\n"
                f"‚öôÔ∏è <b>–ü—Ä–æ—á–∞—è —Ç–µ—Ö–Ω–∏–∫–∞ –∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ:</b> {equip_qty} –µ–¥.\n"
                f"üìä <b>–í—Å–µ–≥–æ:</b> {total} –µ–¥.\n\n"
                f"üìà <b>–°–æ—Å—Ç–æ—è–Ω–∏—è ‚Äî –∞–≤—Ç–æ—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç:</b>\n"
                f"{fmt_status_distribution(status_auto_region)}\n\n"
                f"üìà <b>–°–æ—Å—Ç–æ—è–Ω–∏—è ‚Äî –ø—Ä–æ—á–∞—è —Ç–µ—Ö–Ω–∏–∫–∞ –∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ:</b>\n"
                f"{fmt_status_distribution(status_equip_region)}"
                f"{types_block}\n"
                f"üèôÔ∏è <b>–í—ã–±–µ—Ä–∏ —Ä–∞–π–æ–Ω –¥–ª—è –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏</b>"
            )

            kb = create_districts_keyboard(df_region, region)
            await safe_edit_message(c.message, text, reply_markup=kb)

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ show_region_summary: {e}")
            await c.message.edit_text("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö")

    @dp.message(F.text == "üìä –û–±—â–µ–µ –ø–æ —Ä–µ—Å–ø—É–±–ª–∏–∫–µ")
    async def types_all(m: types.Message):
        try:
            loading_msg = await m.answer("üîÑ –ó–∞–≥—Ä—É–∂–∞—é –¥–∞–Ω–Ω—ã–µ...")
            df = await get_df_async(None, force_refresh=False)
            types_df = all_types_summary(df)

            auto_qty, equip_qty, total = summarize_republic_categories(df)

            if df.empty or "type_normalized" not in df.columns:
                auto_df = pd.DataFrame(columns=df.columns)
                equip_df = pd.DataFrame(columns=df.columns)
            else:
                types = df["type_normalized"].astype(str)
                mask_equipment = types.apply(is_equipment_type)
                auto_df = df[~mask_equipment].copy()
                equip_df = df[mask_equipment].copy()

            status_auto = get_status_distribution_any(auto_df)
            status_equip = get_status_distribution_any(equip_df)

            result = (
                "üìä <b>–û–±—â–µ–µ –ø–æ —Ä–µ—Å–ø—É–±–ª–∏–∫–µ</b>\n\n"
                f"üöó <b>–ê–≤—Ç–æ—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç:</b> {auto_qty} –µ–¥.\n"
                f"‚öôÔ∏è <b>–ü—Ä–æ—á–∞—è —Ç–µ—Ö–Ω–∏–∫–∞ –∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ:</b> {equip_qty} –µ–¥.\n"
                f"üìä <b>–í—Å–µ–≥–æ:</b> {total} –µ–¥.\n\n"
                f"üìà <b>–°–æ—Å—Ç–æ—è–Ω–∏—è ‚Äî –∞–≤—Ç–æ—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç:</b>\n"
                f"{fmt_status_distribution(status_auto)}\n\n"
                f"üìà <b>–°–æ—Å—Ç–æ—è–Ω–∏—è ‚Äî –ø—Ä–æ—á–∞—è —Ç–µ—Ö–Ω–∏–∫–∞ –∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ:</b>\n"
                f"{fmt_status_distribution(status_equip)}\n\n"
            )

            result += "üì≠ –î–∞–Ω–Ω—ã—Ö –Ω–µ—Ç" if types_df.empty else fmt_table(types_df, COL_TYPE)

            await loading_msg.delete()
            await m.answer(result)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ types_all: {e}")
            await m.answer("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö")

    @dp.message(F.text == "üîé –ü–æ—Å—á–∏—Ç–∞—Ç—å –ø–æ —Ç–∏–ø—É")
    async def ask_type(m: types.Message):
        try:
            loading_msg = await m.answer("üîÑ –ó–∞–≥—Ä—É–∂–∞—é —Å–ø–∏—Å–æ–∫ —Ç–∏–ø–æ–≤ —Ç–µ—Ö–Ω–∏–∫–∏...")
            df_all = await get_df_async(None, force_refresh=False)
            types_df = all_types_summary(df_all)
            if types_df.empty:
                await loading_msg.delete()
                await m.answer("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ —Ç–µ—Ö–Ω–∏–∫–µ")
                return
            kb, valid_types = create_types_keyboard(types_df)
            if valid_types == 0:
                await loading_msg.delete()
                await m.answer("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Ç–µ—Ö–Ω–∏–∫–∏")
                return
            await loading_msg.delete()
            await m.answer("üîé –í—ã–±–µ—Ä–∏ —Ç–∏–ø —Ç–µ—Ö–Ω–∏–∫–∏:", reply_markup=kb)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ ask_type: {e}")
            await m.answer("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ç–∏–ø–æ–≤ —Ç–µ—Ö–Ω–∏–∫–∏")

    @dp.message(F.text == "üì° GPS-—É—á—ë—Ç –ø–æ –æ–±–ª–∞—Å—Ç—è–º")
    async def trackers_by_regions(m: types.Message):
        try:
            loading_msg = await m.answer("üì° –°—á–∏—Ç–∞—é —Ç–µ—Ö–Ω–∏–∫—É —Å GPS –ø–æ –æ–±–ª–∞—Å—Ç—è–º...")
            df_all = await get_df_async(None, force_refresh=False)
            if df_all.empty:
                await loading_msg.delete()
                await m.answer("üì≠ –î–∞–Ω–Ω—ã—Ö –Ω–µ—Ç")
                return

            df_tr = count_trackers_by_region(df_all)
            total_trackers = int(df_tr["qty"].sum()) if not df_tr.empty else 0

            lines: List[str] = []
            for region in REGION_SHEETS.keys():
                if df_tr.empty:
                    qty = 0
                else:
                    qty = int(df_tr.loc[df_tr["region_name"] == region, "qty"].sum())
                lines.append(f"‚Ä¢ {esc(region)} ‚Äî {qty} –µ–¥.")

            text = (
                f"üì° <b>GPS-—É—á—ë—Ç —Ç–µ—Ö–Ω–∏–∫–∏ –ø–æ –æ–±–ª–∞—Å—Ç—è–º</b>\n"
                f"–í—Å–µ–≥–æ —Ç–µ—Ö–Ω–∏–∫–∏ —Å GPS: <b>{total_trackers}</b> –µ–¥.\n\n"
                + "\n".join(lines)
            )

            await loading_msg.delete()
            await m.answer(text)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ trackers_by_regions: {e}")
            await m.answer("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥—Å—á—ë—Ç–µ GPS-—É—á—ë—Ç–∞ –ø–æ –æ–±–ª–∞—Å—Ç—è–º")

    # --- —Ä–æ—É—Ç–µ—Ä —Å–æ–∫—Ä–∞—â—ë–Ω–Ω—ã—Ö callback_data (—Ü–∏—Ñ—Ä–æ–≤—ã–µ –∫–ª—é—á–∏ put_cb) ---
    @dp.callback_query(F.data.regexp(r"^\d+$"))
    async def router_short_cb(c: types.CallbackQuery):
        payload = get_cb(c.data) or c.data

        if payload.startswith("count_type:"):
            try:
                await c.answer("üìç –ó–∞–≥—Ä—É–∂–∞—é —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –æ–±–ª–∞—Å—Ç—è–º...")
                tech_type = payload.split(":", 1)[1]
                df_all = await get_df_async(None, force_refresh=False)
                region_df = count_type_per_region(df_all, tech_type)
                if region_df.empty:
                    await c.message.edit_text(
                        f"‚ùå –¢–∏–ø ¬´{esc(tech_type)}¬ª –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –¥–∞–Ω–Ω—ã—Ö\n\n"
                        f"<i>–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ: '{esc(normalize_tech_type(tech_type) or '')}'</i>\n"
                        f"<i>–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≤—ã–±—Ä–∞—Ç—å –¥—Ä—É–≥–æ–π —Ç–∏–ø</i>"
                    )
                    return

                kb = InlineKeyboardBuilder()
                for _, row in region_df.iterrows():
                    region = str(row["region_name"])
                    count = int(row["qty"])
                    sub_payload = f"type_region:{tech_type}|{region}"
                    cbid = put_cb(sub_payload)
                    kb.button(text=f"{region} ({count} –µ–¥.)", callback_data=cbid)

                kb.button(text="‚Ü©Ô∏è –ù–∞–∑–∞–¥ –∫ —Ç–∏–ø–∞–º", callback_data="back_to_types")
                kb.adjust(2, 1)

                total = int(region_df["qty"].sum())
                result = f"üìä <b>{esc(tech_type)}</b> ‚Äî –≤—Å–µ–≥–æ {total} –µ–¥.\n–í—ã–±–µ—Ä–∏ –æ–±–ª–∞—Å—Ç—å –¥–ª—è –¥–µ—Ç–∞–ª–µ–π:"
                await safe_edit_message(c.message, result, reply_markup=kb.as_markup())
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ handle count_type: {e}")
                await c.message.edit_text("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞")
            return

        if payload.startswith("type_region:"):
            try:
                await c.answer("üîç –ó–∞–≥—Ä—É–∂–∞—é –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é...")
                data = payload.split(":", 1)[1]
                tech_type, region = data.split("|")
                df_all = await get_df_async(None, force_refresh=False)

                status_distribution = get_status_distribution_for_type_region(df_all, tech_type, region)
                city_status_distribution = get_detailed_city_status(df_all, tech_type, region)

                normalized_type = normalize_tech_type(tech_type)
                total_mask = (df_all["region_name"] == region) & (df_all["type_normalized"] == normalized_type)
                total_count = int(df_all.loc[total_mask, "qty"].sum())

                result = (
                    f"üîç <b>–î–µ—Ç–∞–ª–∏ –ø–æ {esc(tech_type)}</b>\n"
                    f"üìç <b>–†–µ–≥–∏–æ–Ω:</b> {esc(region)}\n"
                    f"üìä <b>–í—Å–µ–≥–æ –≤ —Ä–µ–≥–∏–æ–Ω–µ:</b> {total_count} –µ–¥.\n\n"
                    f"üìà <b>–ò—Ç–æ–≥–æ –ø–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è–º:</b> {summarize_overall_status(status_distribution)}\n\n"
                    f"üèôÔ∏è <b>–î–µ—Ç–∞–ª–∏ –ø–æ –≥–æ—Ä–æ–¥–∞–º/—Ä–∞–π–æ–Ω–∞–º</b>\n"
                    f"(üü© –Ø—Ä–æ–∫–ª–∏ | üü® –¢–∞—ä–º–∏—Ä—Ç–∞–ª–∞–± | üü• –Ø—Ä–æ–∫—Å–∏–∑):\n\n"
                )
                if city_status_distribution:
                    result += fmt_detailed_city_status(city_status_distribution)
                else:
                    result += "üì≠ –ù–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ –≥–æ—Ä–æ–¥–∞–º"

                kb = InlineKeyboardBuilder()
                back_id = put_cb(f"count_type:{tech_type}")
                kb.button(text="‚Ü©Ô∏è –ù–∞–∑–∞–¥ –∫ —Ä–µ–≥–∏–æ–Ω–∞–º", callback_data=back_id)
                kb.button(text="üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="main_menu")
                kb.adjust(1)

                await safe_edit_message(c.message, result, reply_markup=kb.as_markup())
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ handle type_region: {e}")
                await c.message.edit_text("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–µ—Ç–∞–ª–µ–π")
            return

        if payload.startswith("district:"):
            try:
                await c.answer("üèôÔ∏è –ó–∞–≥—Ä—É–∂–∞—é –¥–∞–Ω–Ω—ã–µ –ø–æ —Ä–∞–π–æ–Ω—É...")

                data = payload.split(":", 1)[1]
                region, district = data.split("|", 1)

                df_region = await get_df_async(region, force_refresh=False)
                if df_region.empty:
                    await c.message.answer(
                        f"üì≠ –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±–ª–∞—Å—Ç–∏ <b>{esc(region)}</b>",
                    )
                    return

                sub = df_region[df_region["city_district"] == district]
                if sub.empty:
                    await c.message.answer(
                        f"üì≠ –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞–π–æ–Ω–∞ <b>{esc(district)}</b> –≤ –æ–±–ª–∞—Å—Ç–∏ {esc(region)}"
                    )
                    return

                auto_qty, equip_qty, total = summarize_district_categories(df_region, district)
                status_df = get_status_distribution_any(sub)

                types_block = (
                    "\nüìã <b>–¢–∏–ø—ã —Ç–µ—Ö–Ω–∏–∫–∏ –≤ —Ä–∞–π–æ–Ω–µ (—Å —Å–æ—Å—Ç–æ—è–Ω–∏—è–º–∏):</b>\n"
                    f"{fmt_types_with_statuses(sub)}"
                )

                text = (
                    f"üèôÔ∏è <b>–†–∞–π–æ–Ω:</b> {esc(district)}\n"
                    f"üìç <b>–û–±–ª–∞—Å—Ç—å:</b> {esc(region)}\n\n"
                    f"üöó <b>–ê–≤—Ç–æ—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç:</b> {auto_qty} –µ–¥.\n"
                    f"‚öôÔ∏è <b>–ü—Ä–æ—á–∞—è —Ç–µ—Ö–Ω–∏–∫–∞ –∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ:</b> {equip_qty} –µ–¥.\n"
                    f"üìä <b>–í—Å–µ–≥–æ:</b> {total} –µ–¥.\n\n"
                    f"üìà <b>–°–æ—Å—Ç–æ—è–Ω–∏—è (–≤—Å–µ–≥–æ –ø–æ —Ä–∞–π–æ–Ω—É):</b>\n"
                    f"{fmt_status_distribution(status_df)}"
                    f"{types_block}"
                )

                kb = InlineKeyboardBuilder()
                kb.button(text="‚Ü©Ô∏è –ù–∞–∑–∞–¥ –∫ –æ–±–ª–∞—Å—Ç–∏", callback_data=f"region:{region}")
                kb.button(text="üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="main_menu")
                kb.adjust(1)
                await c.message.answer(text, reply_markup=kb.as_markup())
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ district-handler: {e}")
                await c.message.answer("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ —Ä–∞–π–æ–Ω—É")
            return

        await c.answer("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ", show_alert=False)

    @dp.callback_query(F.data == "main_menu")
    async def handle_main_menu(c: types.CallbackQuery):
        await c.answer("üè† –í–æ–∑–≤—Ä–∞—â–∞—é—Å—å –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é...")
        await start_cmd(c.message)

    @dp.callback_query(F.data == "back_to_regions")
    async def handle_back_to_regions(c: types.CallbackQuery):
        await c.answer("üìç –í–æ–∑–≤—Ä–∞—â–∞—é—Å—å –∫ —Å–ø–∏—Å–∫—É –æ–±–ª–∞—Å—Ç–µ–π...")
        await choose_region(c.message)

    @dp.callback_query(F.data == "back_to_types")
    async def handle_back_to_types(c: types.CallbackQuery):
        await c.answer("üîé –í–æ–∑–≤—Ä–∞—â–∞—é—Å—å –∫ —Å–ø–∏—Å–∫—É —Ç–∏–ø–æ–≤...")
        await ask_type(c.message)

    @dp.message(F.text == "üîÑ –û–±–Ω–æ–≤–∏—Ç—å –∫–µ—à")
    async def clear_cache_cmd(m: types.Message):
        global CACHE
        CACHE.clear()
        await m.answer("üîÑ –ö–µ—à –æ—á–∏—â–µ–Ω! –î–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤—è—Ç—Å—è –ø—Ä–∏ —Å–ª–µ–¥—É—é—â–µ–º –∑–∞–ø—Ä–æ—Å–µ.")

    @dp.message(Command("clear_cache"))
    async def clear_cache_command(m: types.Message):
        global CACHE
        CACHE.clear()
        await m.answer("üîÑ –ö–µ—à –æ—á–∏—â–µ–Ω! –î–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤—è—Ç—Å—è –ø—Ä–∏ —Å–ª–µ–¥—É—é—â–µ–º –∑–∞–ø—Ä–æ—Å–µ.")

    @dp.message(Command("stats"))
    async def stats_cmd(m: types.Message):
        try:
            df_all = await get_df_async(None, force_refresh=False)
            total_records = len(df_all)
            total_qty = int(df_all["qty"].sum()) if not df_all.empty else 0
            cache_size = len(CACHE)

            types_df = all_types_summary(df_all)
            unique_types = len(types_df) if not types_df.empty else 0

            trackers_total = 0
            if not df_all.empty and "has_tracker" in df_all.columns:
                try:
                    trackers_total = int(df_all.loc[df_all["has_tracker"], "qty"].sum())
                except Exception as err:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥—Å—á—ë—Ç–µ GPS –≤ stats_cmd: {err}")

            status_stats = ""
            if "status_normalized" in df_all.columns and not df_all.empty:
                status_df = df_all.groupby("status_normalized")["qty"].sum().sort_values(ascending=False)
                status_stats = "\n".join([f"‚Ä¢ {esc(st)}: {int(q)} –µ–¥." for st, q in status_df.items()])

            next_update = "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
            if "ALL" in CACHE:
                _, exp = CACHE["ALL"]
                mins = max(0, int((exp - datetime.now()).total_seconds() // 60))
                next_update = f"{mins} –º–∏–Ω"

            stats_text = (
                f"üìà <b>–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–æ—Ç–∞</b>\n\n"
                f"‚Ä¢ –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {total_records}\n"
                f"‚Ä¢ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Ö–Ω–∏–∫–∏: {total_qty} –µ–¥.\n"
                f"‚Ä¢ –¢–µ—Ö–Ω–∏–∫–∏ —Å GPS: {trackers_total} –µ–¥.\n"
                f"‚Ä¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Ç–µ—Ö–Ω–∏–∫–∏: {unique_types}\n"
                f"‚Ä¢ –†–∞–∑–º–µ—Ä –∫–µ—à–∞: {cache_size} —ç–ª–µ–º–µ–Ω—Ç–æ–≤\n"
                f"‚Ä¢ –°–ª–µ–¥—É—é—â–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–µ—à–∞: {esc(next_update)}\n\n"
            )
            if status_stats:
                stats_text += f"<b>üìä –°–æ—Å—Ç–æ—è–Ω–∏–µ —Ç–µ—Ö–Ω–∏–∫–∏ (–≤—Å–µ–≥–æ):</b>\n{status_stats}"

            await m.answer(stats_text)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ stats_cmd: {e}")
            await m.answer("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏")

    @dp.message(Command("help"))
    async def help_command(m: types.Message):
        await help_cmd(m)

    @dp.message()
    async def handle_other_messages(m: types.Message):
        await m.answer(
            "ü§ñ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫–∏ –º–µ–Ω—é –∏–ª–∏ –∫–æ–º–∞–Ω–¥—ã:\n"
            "/start ‚Äî –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é\n"
            "/help ‚Äî —Å–ø—Ä–∞–≤–∫–∞",
            reply_markup=main_menu_kb()
        )

    try:
        await bot.delete_webhook(drop_pending_updates=True)
        logger.info("üöÄ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω: async I/O, –æ–±–ª–∞—Å—Ç–∏‚Üí—Ä–∞–π–æ–Ω—ã, —Å—Ç–∞—Ç—É—Å—ã, –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ç–µ—Ö–Ω–∏–∫–∏, GPS-—É—á—ë—Ç")
        await dp.start_polling(bot, allowed_updates=dp.resolve_used_update_types())
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –±–æ—Ç–∞: {e}")
    finally:
        await bot.session.close()


if __name__ == "__main__":
    asyncio.run(main())
